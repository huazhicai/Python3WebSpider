## scrapy weibo 


- **爬虫目标**
    - 新浪微博用户的公开基本信息，如用户昵称、头像、用户的关注、粉丝列表以及发布的微博内容
    
- **准备工作**
    - ip代理池，cookies池已经实现，安装pymongo
    
- **爬取思路**
    - 首先我们要实现用户的大规模爬取。
    - 采取的方式是以微博的几个大V为起点，爬取他们各自的粉丝和关注列表
    - 然后获取粉丝的关注列表和粉丝，以此类推，这样就可以实现递归爬取。
    - 通过这种方式，我们可以得到用户的唯一ID，再根据ID获取每个用户发布的微博
    
- **爬取分析**

- **cookies**
    - 爬虫代理和cookeis代理优先级要比他们默认的优先级高才行
    - 都小于700吧
